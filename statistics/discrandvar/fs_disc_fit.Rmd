---
title: "Estimate Parameters for Discrete Distributions"
titleshort: "Estimate Parameters for Discrete Distributions"
description: |
  Given a discrete random variable, estimate the parameters of a discrete probability function. 
  Given a discrete random variable, generated from discretizing a normal random variable, estimate binomial parameters that provide the best fit for the observe data.
core:
  - package: r
    code: |
      %*%
      which.max
  - package: stats
    code: |
      dbinom()
  - package: dplyr
    code: |
      min_rank()
date: 2022-07-23
date_start: 2021-06-13
output:
  pdf_document:
    pandoc_args: '../../_output_kniti_pdf.yaml'
    includes:
      in_header: '../../preamble.tex'
  html_document:
    pandoc_args: '../../_output_kniti_html.yaml'
    includes:
      in_header: "../../hdga.html"
always_allow_html: true
urlcolor: blue
---

### Binomial Probability Function Given Observed Discrete Probabilities

```{r global_options, include = FALSE}
try(source("../../.Rprofile"))
```

`r text_shared_preamble_one`
`r text_shared_preamble_two`
`r text_shared_preamble_thr`

#### Estimate Chance of Success given Fixed Number of Trials

We observe $\left\{P(x_i)\right\}_{i=0}^{N}$, where $\sum_{i=0}^N P(x_i) = 1$. Note this is observing probabilities not at $N$ outcomes but $N+1$ outcomes starting at $i=0$. What is the [binomial probability function](https://fanwangecon.github.io/Stat4Econ/probability_discrete/htmlpdfr/binomial.html) that would fit the observed data the best? 

There are two parameters of the binomial distribution, $N$, which is the "number of trials", and $\theta$, which is the probability of success for each trial. In this section, we treat $N$ as already observed, so we only need to pick the $\theta$ that provides the best fit between the binomial probabilities generated (given $p$), and the data. 

For the household that currently has zero child, one interpretation of this fitting procedure is that there are for this household $N$ "trials"/chances of getting a child, and $\theta$ is the chance of new arrival during each trial. By using the binomial distribution, we are assuming that the chance of new child arrival from across trials is independent, and the chances of arrival is identical during each trail. The interpretation is less clear when are looking a household that already has more than zero children. Overall, the purpose here is to use a low-dimensional procedure to provide a good fit to the observed probabilities, and to be able to easily adjust the resulting parameters across observed discrete probabilities to change some aggregate outcome of interest (e.g., [fertility](https://fanwangecon.github.io/R4Econ/amto/matrix/htmlpdfr/fs_mat_demo_trans.html)).

We fit with a likelihood based approach. First, the likelihood function is:

$$
\begin{aligned}
\mathcal{L}(\theta) = 
    \Pi_{i=0}^N    
    \left(
    \frac{N!}{\left(N - i\right)! i!}
    \cdot \theta^{ i} \cdot \left(1-\theta\right)^{N- i}
    \right)^{P(x_i)}
\end{aligned}
$$

Second, we write the log likelihood. Note that we observe $P(x_i)$ from the data. 

$$
\begin{aligned}
\ln\left(\mathcal{L}(\theta)\right) &= 
\sum_{i=0}^N
    P(x_i)
    \ln
    \left(
    \frac{N!}{\left(N- i\right)! i!}
    \cdot \theta^{ i} \cdot \left(1-\theta\right)^{N- i}
    \right)\\
&= 
\sum_{i=0}^N
\left(
P(x_i)\ln\left(\frac{N!}{\left(N-i\right)!i!}\right) +
P(x_i) i \ln\left(\theta\right) + 
P(x_i)(N-i)\ln\left(1-\theta\right)
\right)
\end{aligned}
$$

Third, we take the derivative of the log likelihood with respect to the parameter of interest $\theta$. 

$$
\begin{aligned}
\frac{d \ln\left(\mathcal{L}(\theta)\right)
}{
d \theta
} =
\sum_{i=0}^N
\left(
    \frac{P(x_i) i}{\theta}
    - 
    \frac{P(x_i)(N- i)}{1-\theta}
\right)
\end{aligned}
$$

Fourth, we set the derivative above to be equal to zero. 

$$
\begin{aligned}
\frac{\sum_{i=0}^N P(x_i) \cdot i}{\theta} &=
\frac{\sum_{i=0}^N P(x_i)(N-i)}{1-\theta}\\
\sum_{i=0}^N P(x_i) \cdot i - \theta \cdot \sum_{i=0}^N P(x_i) \cdot i &=
\theta \cdot \sum_{i=0}^N P(x_i)(N- i)\\
\theta &= \frac{
\sum_{i=0}^N P(x_i) \cdot i
}{
\sum_{i=0}^N 
\left(P(x_i)(N- i) + P(x_i) \cdot i\right)
}\\
\theta &= \frac{
\sum_{i=0}^N P(x_i) \cdot i
}{
N \cdot\sum_{i=0}^N P(x_i)
}\\
\theta &= \frac{
\sum_{i=0}^N P(x_i) \cdot i
}{
N 
}
\end{aligned}
$$

Fifth, given the derivation above, we have found the maximizing parameter of the likelihood function. The maximizer is the ratio between the mean (probability-weighted average) of the observed discrete data, divided by the $N$, where $N+1$ is the number of discrete data points observed. 

$$
\arg\max_{\theta} \ln(\mathcal{L}(\theta)) 
= \frac{
\sum_{i=0}^N P(x_i) \cdot i
}{
N 
}
$$

Suppose that the observe probability data is measured without error from a binomial distribution, in that case [$\sum_{i=0}^N P(x_i=i) \cdot i = \mu_{\text{binomial}} = N\cdot \theta$](https://fanwangecon.github.io/Stat4Econ/probability_discrete/htmlpdfr/binomial.html#2_binomial_experiment), which means the mean number of "wins" is the number of "trials" times the probability of winning each trial. 

##### Approximating Transition Probability

As an example, we now proceed with an example. Below we have a 5 by 5 transition matrix, where each of the row sums up to 1. We compute a binomial probability function to fit the probabilities in each of the rows of the matrix. 

This matrix example below is used as the household structure kids transition matrix for a particular set of 18 year old individuals [Nygaard, SÃ¸rensen, and Wang (2022)](https://www.sciencedirect.com/science/article/abs/pii/S0165188922000574?via%3Dihub) ([preprint pdf](https://arxiv.org/pdf/2204.03799.pdf)). Each row corresponds to a different household size in the current period, and each column is the chance of transitioning to different household sizes in the next period.

First, generate the input matrixes. 

```{r}
# Construct transition matrix (row sums to 1, 5 by 5)
mt_pi_kids_trans <- matrix(
    data = c(
        0.8929,    0.1045,    0.0026,    0.0000,    0.0000,
        0.0547,    0.6704,    0.2708,    0.0040,    0.0001,
        0.0014,    0.0571,    0.7931,    0.1462,    0.0022,
        0.0000,    0.0009,    0.0748,    0.7885,    0.1358,
        0.0000,    0.0000,    0.0008,    0.0593,    0.9399
    ),
    nrow = 5, ncol = 5,
    byrow = TRUE
)
# check row sum
rowSums(mt_pi_kids_trans)
# Construct the x vector, this is (5 by 1)
# we have x_0, to x_4, for the 5 columns
# x_0 = 0, and x_4 = 4
ar_x <- matrix(c(0, 1, 2, 3, 4), nrow = 5, ncol = 1)
```

Second, estimate the $\theta$ parameters for each household size (row) this period.

```{r}
# (5 by 5) times (5 by 1) generates (5 by 1)
# they correspond to 5 different \sum_{i=0}^N P(x_i)x_i
# Note divide by 4 not 5
ar_row_expected_x <- (mt_pi_kids_trans %*% ar_x) / (4)

# estimated thetas have been found
ar_theta_esti <- ar_row_expected_x
print(ar_theta_esti)
```

Third, generate the binomial probabilities and construct the 5 by 5 matrix based on that. 

```{r}
# Generate Binomial
mt_dbinom_approx <- t(sapply(
    ar_theta_esti, dbinom,
    x = seq(0, 4), size = 4
))
# Present
print(round(mt_dbinom_approx, 3))
```

Evaluating the results, we see that the fit this provides a good fit for the first and fifth rows, but the fit for the three middle rows seem to be substantially worse. The observed transition mass is much more persistent than the fitted transition. 

#### Estimate Chance of Success and the Number of Trials

In contrast to the prior section, in this section, we will allow for both the "Number of Trials" and the "Chance of Success" parameters to vary to provide a better fit between transition probabilities and the data. 

Since the Binomial distribution is approximately normal, so in principle, we should be able to use the binomial to fit a discretized normal random variables, which transition probabilities seem to generally approximate. A problem with the prior section is that the "number of trials" is only 4, which is very small. At this level, the binomial/normal approximation does not work well.

We will adjust our likelihood based estimation objective function. We assume that the observed probabilities are aggregated based on underlying subgroups. Our new likelihood function is:

$$
\begin{aligned}
\mathcal{L}(\theta, M) = 
    \Pi_{i=0}^N    
    \left(
    \sum_{j=0}^{M-1} P_{\text{binom}}
        \left(
            \underbrace{\left(i \times M + j\right)}_{\text{Number of success}}; 
            \overbrace{\theta}^{\text{suc. prb.}}, 
            \underbrace{\left(N+1\right)\times M-1}_{\text{Number of trials}}
        \right)
    \right)^{P(x_i)}
\end{aligned}
$$

In the equation above, $P_{\text{binom}}$ follows the same binomial probability formula as before, it is evaluated at the "Number of successes", given success probability $\theta$ and the "Number of Trials". To be consistent with the prior example, $N+1$ is the number of discrete observed probability categories. The new parameter $M \in \mathbb{N}$ is an integer that determines how many discrete evenly-spaced sub-categories are within each of the observed $N+1$ probability categories. 

Given one set of observed probabilities to fit, the constrained maximum likelihood optimization problem is now: 

$$
\begin{aligned}
\max_{\substack{
    \theta\in\left(0, 1\right)\\
    M\in \mathbb{N}
}}
\mathcal{L}(\theta, M)
\end{aligned}
$$

When we have $K$ sets of observed probabilities as in the example earlier with the five transition probabilities, we could allow for $K$ different $\theta$ parameters, but constrain all $K$ transitions to share the same $M$. In that case, the constrained optimization problem becomes:

$$
\begin{aligned}
\max_{\substack{
    \left\{\theta_k\in\left(0, 1\right)\right\}_{k=1}^K\\
    M\in \mathbb{N}
}}
\Pi_{k=1}^K
\mathcal{L}(\theta_k, M)
\end{aligned}
$$

We do not, however, have analytical solutions for this optimization problem. We will solve for this problem numerically. 

##### Optimal Theta Given M

For the numerical procedure, given $M$, we will find the best fitting $\theta$, then we increment $M$, and we compare fit and best fitting $\theta$ across $M$. 

First, we construct the likelihood function that considers the sum of probability between most adjacent groups. The function computes the log likelihood, given $N+1$ points of probability, $\theta$ values, and $M$. 

```{r}
#' Probability group aggregator
#' @param it_n Integer such that it_n + 1 is the number of observed
#' discrete outcomes.
#' @param it_m Integer such that \eqn{(it_n + 1) * it_m - 1} is the
#' number of trials for a binomial experiment.
ffi_pbinom_group_theta_m <-
    function(fl_chance_success = 0.52,
             it_n = 4,
             it_m = 8) {

        # nbrtrl = number of trials
        it_nbrtrl <- (it_n + 1) * it_m - 1

        # Evaluate probability
        ar_dbinom <- dbinom(
            seq(0, it_nbrtrl),
            size = it_nbrtrl, prob = fl_chance_success
        )
        mt_dbinom <- matrix(
            ar_dbinom,
            nrow = it_n + 1, ncol = it_m,
            byrow = TRUE
        )

        # Sum probabilities each sub-groups
        ar_dbinom_grouped <- rowSums(mt_dbinom)

        return(ar_dbinom_grouped)
    }
# log-likelihood generator
# at the default value, the generated probabilities are similar to observed.
ffi_pbinom_lnlk_theta_m <-
    function(ar_drm_prob = c(0.0014, 0.0571, 0.7931, 0.1462, 0.0022),
             fl_chance_success = 0.50,
             it_m = 1) {

        # it_n = (N+1)*M-1
        it_n <- length(ar_drm_prob) - 1

        # Call the grouping function
        ar_dbinom_grouped <- ffi_pbinom_group_theta_m(
            fl_chance_success = fl_chance_success,
            it_n = it_n,
            it_m = it_m
        )

        # Log of group-probabilities
        ar_dbinom_grouped_ln <- log(ar_dbinom_grouped)

        # Log likelihood
        fl_ln_likelihood <- ar_dbinom_grouped_ln %*% ar_drm_prob
        return(fl_ln_likelihood)
    }
```

Second, test the function above with different theta values. Note that given the input example probability array and fixing $M=1$, choosing among 9 different $\theta$ values from $0.1$ to $0.9$, we find that $\theta=0.5$ provides the highest likelihood. It is clear that the likelihood function is single-peaked and smooth in the example here as we vary over $\theta$ here.

```{r}
# Test the function with different theta values
ar_drm_prob <- c(0.0014, 0.0571, 0.7931, 0.1462, 0.0022)
ar_fl_theta <- seq(0.1, 0.9, length.out = 9)
it_m <- 1
ar_ln_likelihood <- sapply(
    ar_fl_theta,
    ffi_pbinom_lnlk_theta_m,
    ar_drm_prob = ar_drm_prob,
    it_m = it_m
)
# Label and print
mt_theta_likelihood <- cbind(ar_fl_theta, ar_ln_likelihood)
colnames(mt_theta_likelihood) <- c("theta", "log_likelihood")
kable(as_tibble(mt_theta_likelihood) %>%
    mutate(rank = min_rank(desc(log_likelihood))), caption = paste(
    "Log likelihood evaluated at varying",
    "theta values, given some vector",
    "of observed probabilities, and",
    paste0("M=", it_m),
    separator = " "
)) %>% kable_styling_fc()
```  

Third, construct likelihood with different values of $M$. Note that we are using $\theta=0.5$, which we found from the previous step as the likelihood maximizing parameter value given $M=1$. The table that we generate below shows that the likelihood is maximized at $M=7$. It is clear that the likelihood function is single-peaked and smooth in the example here as we vary over $M$

```{r}
# Test the function with different theta values
ar_drm_prob <- c(0.0014, 0.0571, 0.7931, 0.1462, 0.0022)
fl_theta <- 0.50
ar_it_m <- seq(1, 10)
ar_ln_likelihood <- sapply(
    ar_it_m,
    ffi_pbinom_lnlk_theta_m,
    ar_drm_prob = ar_drm_prob,
    fl_chance_success = fl_theta
)
# Label and print
mt_m_likelihood <- cbind(ar_it_m, ar_ln_likelihood)
colnames(mt_m_likelihood) <- c("M", "log_likelihood")
kable(as_tibble(mt_m_likelihood) %>%
    mutate(rank = min_rank(desc(log_likelihood))), caption = paste(
    "Log likelihood evaluated at varying",
    "M values, given some vector",
    "of observed probabilities, and",
    paste0("theta=", fl_theta),
    separator = " "
)) %>% kable_styling_fc()
```

Fourth, we develop a grid evaluator of the function we just created. Given a vector of different $\theta$ values, we find the index that maximizes the likelihood, and we create new lower and upper bound that are around the maximizing grid point for $\theta$. 

```{r}
# Evaluate likelihood along a grid and find the
# surrounding points around the maximizing grid point.
ffi_pbinom_lnlk_theta_m_grid <-
    function(ar_drm_prob = c(0.0014, 0.0571, 0.7931, 0.1462, 0.0022),
             it_m = 8,
             it_p_success_grid_len = 10,
             fl_min_p_success = 1e-5,
             fl_max_p_success = 1 - 1e-5) {

        # Theta array rebuilt
        ar_fl_theta <- seq(
            fl_min_p_success,
            fl_max_p_success,
            length.out = it_p_success_grid_len
        )

        # Evaluate likelihood
        ar_ln_likelihood <- sapply(
            ar_fl_theta,
            ffi_pbinom_lnlk_theta_m,
            ar_drm_prob = ar_drm_prob,
            it_m = it_m
        )
        # Find min grid
        it_max_idx <- which.max(ar_ln_likelihood)
        fl_max_val <- ar_ln_likelihood[it_max_idx]

        # Find lower and upper bound
        fl_min_p_succcess_new <- ar_fl_theta[
            max(it_max_idx - 1, 1)
        ]
        fl_max_p_succcess_new <- ar_fl_theta[
            min(it_max_idx + 1, it_p_success_grid_len)
        ]

        # return
        return(list(
            fl_max_val = fl_max_val,
            fl_min_p_succcess_new = fl_min_p_succcess_new,
            fl_max_p_succcess_new = fl_max_p_succcess_new
        ))
    }
# test
ffi_pbinom_lnlk_theta_m_grid()
```

Fifth, given $N+1$ points of data, and given $M$, we find the best fit $\theta$ value. We loop iteratively over grid several times. For an example of this iterative-grid algorithm, see [Find Maximum By Iterating Over Grids](https://fanwangecon.github.io/R4Econ/optimization/root_bisect/htmlpdfr/fs_optimize_grid_loop.html).

```{r}
# Find likelihood maximizing theta, given M
ffi_pbinom_lnlk_estitheta_fixm <-
    function(ar_drm_prob = c(0.0014, 0.0571, 0.7931, 0.1462, 0.0022),
             it_m = 1,
             verbose = FALSE) {

        # Initialize min and max and tolerance criteria
        fl_min_p_success_cur <- 1e-5
        fl_max_p_success_cur <- 1 - 1e-5
        it_p_success_grid_len <- 10
        fl_tol <- 1e-6
        it_max_iter <- 10

        # Initialize initial gaps etc
        fl_gap <- 1e5
        fl_min_ln_like_last <- 1e5
        it_iter <- 0

        # Iteratively loop over grid to find the maximum by zooming in
        while ((fl_gap > fl_tol) && it_iter <= it_max_iter) {

            # Iterator counts up
            it_iter <- it_iter + 1
            if (verbose) print(paste0("it_iter=", it_iter))

            # build array
            ls_find_max <- ffi_pbinom_lnlk_theta_m_grid(
                ar_drm_prob = ar_drm_prob,
                it_m = it_m,
                it_p_success_grid_len = it_p_success_grid_len,
                fl_min_p_success = fl_min_p_success_cur,
                fl_max_p_success = fl_max_p_success_cur
            )

            # Min objective value current
            fl_max_ln_like <- ls_find_max$fl_max_val
            # Find new lower and upper bound
            fl_min_p_success_cur <- ls_find_max$fl_min_p_succcess_new
            fl_max_p_success_cur <- ls_find_max$fl_max_p_succcess_new
            if (verbose) print(paste0("min_p_succ_cur=", fl_min_p_success_cur))
            if (verbose) print(paste0("max_p_succ_cur=", fl_max_p_success_cur))

            # Compare
            fl_gap <- abs(fl_max_ln_like - fl_min_ln_like_last)
            fl_max_ln_like_last <- fl_max_ln_like
            if (verbose) print(paste0("fl_gap=", fl_gap))
        }

        # Find estimate for theta
        fl_p_success_argmax <- (fl_min_p_success_cur + fl_max_p_success_cur) / 2

        # return
        return(list(
            fl_p_success_argmax = fl_p_success_argmax,
            fl_max_ln_like = fl_max_ln_like
        ))
    }
# Test with different M values
ar_drm_prob <- c(0.0014, 0.0571, 0.7931, 0.1462, 0.0022)
ffi_pbinom_lnlk_estitheta_fixm(ar_drm_prob = ar_drm_prob, it_m = 1)
ffi_pbinom_lnlk_estitheta_fixm(ar_drm_prob = ar_drm_prob, it_m = 5)
ffi_pbinom_lnlk_estitheta_fixm(ar_drm_prob = ar_drm_prob, it_m = 9)
```

##### Optimal M given Optimal Theta Conditional on M

We now proceed to find the optimum $M$ value, assuming that multiple probability vectors can have different $\theta$ but must share $M$. 

First, we find the optimizing $\theta$ that differs for each of the discrete probability vectors.

```{r}
# Find likelihood maximizing theta, given M
ffi_pbinom_lnlk_estijnt <-
    function(mt_drm_prob = matrix(
                 data = c(
                     0.8929,    0.1045,    0.0026,    0.0000,    0.0000,
                     0.0547,    0.6704,    0.2708,    0.0040,    0.0001
                 ),
                 nrow = 2, ncol = 5, byrow = TRUE
             ),
             verbose = FALSE) {

        # Initialize min and max and tolerance criteria
        it_drm_set <- dim(mt_drm_prob)[1]
        ar_it_m <- seq(1, 10)

        for (it_i in seq(1, it_drm_set)) {
            ls_estitheta_fixm_res <- sapply(
                ar_it_m,
                ffi_pbinom_lnlk_estitheta_fixm,
                ar_drm_prob = mt_drm_prob[it_i, ]
            )

            mt_estitheta_fixm_res <- t(matrix(
                as.numeric(ls_estitheta_fixm_res),
                nrow = 2, ncol = length(ls_estitheta_fixm_res) / 2
            ))
            mt_estitheta_fixm_res <- cbind(mt_estitheta_fixm_res, ar_it_m)
            colnames(mt_estitheta_fixm_res) <- c("esti_theta", "ln_like", "M")

            tb_estitheta_fixm_res <-
                as_tibble(mt_estitheta_fixm_res) %>%
                mutate(drm_group = it_i)

            if (it_i > 1) {
                tb_estitheta_fixm_res_stack <-
                    bind_rows(
                        tb_estitheta_fixm_res_stack,
                        tb_estitheta_fixm_res
                    )
            } else {
                tb_estitheta_fixm_res_stack <- tb_estitheta_fixm_res
            }
        }

        # Group max
        tb_estitheta_fixm_res_stack <- tb_estitheta_fixm_res_stack %>%
            group_by(drm_group) %>%
            mutate(drm_group_rank = min_rank(desc(ln_like))) %>%
            ungroup()

        # Overall M that maximizes sum of log likelihood
        tb_estitheta_fixm_res_stack <- tb_estitheta_fixm_res_stack %>%
            group_by(M) %>%
            mutate(ln_like_M_sum = sum(ln_like)) %>%
            ungroup() %>%
            mutate(drm_jnt_rank = dense_rank(desc(ln_like_M_sum))) %>%
            arrange(drm_group, M)

        # Return
        return(tb_estitheta_fixm_res_stack)
    }
# Test with full transition matrix
tb_rest_res <- ffi_pbinom_lnlk_estijnt(mt_drm_prob = mt_pi_kids_trans[1:2, ])
kable(tb_rest_res %>% select(-ln_like_M_sum, -drm_jnt_rank),
    caption = paste(
        "Given 2 sets of discrete probabilities (drm-group=1 and =2),",
        "for each drm-group and for each M,",
        "show the estimated theta (esti-theta) that maximizes likelihood,",
        "as well as the maximum likelihood achieved (ln-like).",
        "Show within drm-group likelihood desc rank (drm-group-rank);",
        "There is a (drm-group-rank=1) for each (drm-group),",
        "where we maximize likelihood by adjusting both M and theta",
        "at the same time.",
        "M rows for each set of (drm-group).",
        separator = " "
    )
) %>% kable_styling_fc()
kable(tb_rest_res %>% filter(drm_jnt_rank == 1),
    caption = paste(
        "Given 2 sets of discrete probabilities (drm-group=1 and =2),",
        "pick the M (M)",
        "where the overall likelihood (ln-like-M-sum) summed across",
        "likelihoods (ln-like) from the two sets of discrete probabilities",
        "is maximized (drm-jnt-rank == 1).",
        "Theta differs for each drm-group, but M is shared.",
        separator = " "
    )
) %>% kable_styling_fc()
```

Second, we evaluate the predicted probabilities given our optimizing parameters. 

```{r}
# Estimate for full data input matrix (all 5 rows)
tb_rest_res <- ffi_pbinom_lnlk_estijnt(mt_drm_prob = mt_pi_kids_trans)

# Compute predicted probabilities at maxmizing parameters
mt_dbinom_grouped <-
    apply(
        tb_rest_res %>% filter(drm_jnt_rank == 1),
        1,
        function(row) {
            ffi_pbinom_group_theta_m(
                fl_chance_success = row[["esti_theta"]],
                it_n = (dim(mt_pi_kids_trans)[1] - 1),
                it_m = row[["M"]]
            )
        }
    )
# Show predictions
kable(round(t(mt_dbinom_grouped), 3),
    caption = "Predicted transitions given estimates"
) %>% kable_styling_fc()
# Show data
kable(round(mt_pi_kids_trans, 3),
    caption = "Data transitions probalities"
) %>% kable_styling_fc()
# Show data and prediction differences
kable(round(mt_pi_kids_trans - t(mt_dbinom_grouped), 3),
    caption = "Data transitions probalities - predictions"
) %>% kable_styling_fc()
```

##### Rescale Theta by Common Parameter

Following our discussions here, [Rescale a Fraction Between 0 and 1](https://fanwangecon.github.io/R4Econ/math/solutions/htmlpdfr/fs_rescale.html#11_Rescale_a_Fraction_Between_(0)_and_(1)), we now proceed to test a procedure where we adjust a $\lambda$ parameter, which will each each of the estimated $\theta$ value. Specifially, we have: 

$$
\widehat{\theta}\left(\theta, \lambda\right)= 
\theta \cdot 
      \left(
      \frac{
        \exp\left(\lambda\right)
      }{
        1 + \theta\cdot\left(\exp\left(\lambda\right) - 1\right)
      }
      \right)
$$

First, we define the rescaling function, identical to the rescaling function from [Rescale a Fraction Between 0 and 1](https://fanwangecon.github.io/R4Econ/math/solutions/htmlpdfr/fs_rescale.html#11_Rescale_a_Fraction_Between_(0)_and_(1)).

```{r}
# Construct the formula
ffi_theta_lambda_0t1 <- function(theta, lambda) {
    if (is.finite(exp(lambda))) {
        theta * (exp(lambda) / (1 + theta * (exp(lambda) - 1)))
    } else {
        # If lambda is large, exp(lambda)=inf, ratio above becomes 1
        1
    }
}
```

Second, we create $\widehat{\theta}\left(\theta, \lambda\right)$, with different scaling $\lambda$ values, for the optimizing $\theta$ for each of the drm-groups.

```{r}
# Estimation results
tb_rest_res_opti <- ffi_pbinom_lnlk_estijnt(mt_drm_prob = mt_pi_kids_trans) %>%
    filter(drm_jnt_rank == 1) %>%
    select(esti_theta, M, drm_group, ln_like, ln_like_M_sum)
# Generate theta_hat columns
tb_rest_res_opti_theta_hat <- tb_rest_res_opti %>%
    mutate(
        theta_hat_lambda_n2 = ffi_theta_lambda_0t1(
            theta = esti_theta, lambda = -2
        ),
        theta_hat_lambda_n1 = ffi_theta_lambda_0t1(
            theta = esti_theta, lambda = -1
        ),
        theta_hat_lambda_zr = ffi_theta_lambda_0t1(
            theta = esti_theta, lambda = 0
        ),
        theta_hat_lambda_p1 = ffi_theta_lambda_0t1(
            theta = esti_theta, lambda = +1
        ),
        theta_hat_lambda_p2 = ffi_theta_lambda_0t1(
            theta = esti_theta, lambda = +2
        )
    ) %>%
    select(drm_group, esti_theta, contains("theta_hat"))
# Show data and prediction differences
kable(tb_rest_res_opti_theta_hat,
    caption = paste(
        "Theta transform with different common lambda.",
        "n2 is lambda = -2,",
        "zr is lambda = 0 (theta-hat=theta),",
        "p2 is lambda = +2.",
        separator = " "
    )
) %>% kable_styling_fc()
```